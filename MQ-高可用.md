# MQ 高可用

## RabbitMQ

RabbitMQ 基于**主从模式**（非分布式）高可用

RabbitMQ 有3种模式：单机模式、普通集群模式、镜像集群模式

### 单机模式

单机模式，Demo模式，一般用来本地玩玩，生产环境中不会使用单机模式

### 普通集群模式（无高可用性）

普通集群模式，在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个

**创建的 queue，只会放在一个 RabbitMQ 实例上**，但是每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）

消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来

![mq-7](./images/mq-7.png)

这种方式**没做到所谓的分布式**，就是个普通集群

导致要么消费者每次随机连接一个实例然后拉取数据，要么固定连接那个 queue 所在实例消费数据，前者有**数据拉取的开销**，后者导致**单实例性能瓶颈**

如果存放 queue 的实例宕机了，会导致接下来其他实例就无法从所在实例拉取，如果**开启了消息持久化**，让 RabbitMQ 落地存储消息，**消息不一定会丢**，但需要等这个实例恢复，才可以继续从这个 queue 拉取数据

**没有什么所谓的高可用性**，**该方案主要是提高吞吐量的**，即让集群中多个节点来服务某个 queue 的读写操作

### 镜像集群模式（高可用）

镜像集群模式才是 RabbitMQ 的高可用模式

在镜像集群模式下，创建的 queue，无论元数据还是 queue 里的消息都会**存在于多个实例上**，就是说，每个 RabbitMQ 节点都有这个 queue 的一个**完整镜像**，包含 queue 的全部数据

每次消息发送到 queue 的时候，都会自动把**消息同步**到多个实例的 queue 上

![mq-8](./images/mq-8.png)

**开启镜像集群模式**：RabbitMQ控制台新增**镜像集群模式策略**，指定的时候可以要求数据同步到所有节点，也可以要求同步到指定数量的节点，再次创建 queue 的时候，应用这个策略，就会自动将数据同步到其他的节点上去

**优点**：

+ 任何一个机器宕机了，其它机器（节点）还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据

**缺陷**：

+ 消息需要同步到所有机器上，导致网络带宽压力和消耗很重，性能开销非常大
+ **没有扩展性**，如果某个 queue 负载很重，加机器，新增的机器也包含了这个 queue 的所有数据，并**没有办法线性扩展** queue

## Kafka

Kafka 架构基本描述：由多个 broker 组成，每个 broker 是一个节点；创建一个 topic，这个 topic 可以划分为多个 partition，每个 partition 可以存在于不同的 broker 上，每个 partition 就放一部分数据

**天然的分布式消息队列**，就是说一个 topic 的数据，是**分散放在多个机器上的，每个机器就放一部分数据**

实际上 RabbitMQ 之类的，并不是分布式消息队列，是传统的消息队列，只不过提供了一些集群、HA(High Availability, 高可用性) 的机制而已，RabbitMQ 一个 queue 的数据都是放在一个节点里的，镜像集群下，也是每个节点都放这个 queue 的完整数据

Kafka 0.8 以前，没有 HA 机制，任何一个 broker 宕机， broker 上的 partition 就废了，无法读写，不存在高可用

假设创建了一个 topic，指定其 partition 数量是 3 个，分别在三台机器上，但是，如果第二台机器宕机了，会导致这个 topic 的 1/3 的数据就丢了，因此这个是做不到高可用的

![kafka-before](./images/kafka-before.png)

Kafka 0.8 以后，提供了 HA 机制，就是 replica（复制品） 副本机制

每个 partition 的数据都会同步到其它机器上，形成自己的多个 replica 副本

所有 replica 会选举一个 leader 出来，那么生产和消费都跟这个 leader 打交道，然后其他 replica 就是 follower

写的时候，leader 会负责把数据同步到所有 follower 上去，读的时候就直接读 leader 上的数据即可

**如果可以随意读写每个 follower，那么就要考虑数据一致性的问题**，系统复杂度太高，很容易出问题

Kafka 会均匀地将一个 partition 的所有 replica 分布在不同的机器上，这样才可以提高容错性

![kafka-after](./images/kafka-after.png)

此时的 Kafka 处于高可用状态，如果某个 broker 宕机，并不会丢失数据，因为宕机的 broker 上的数据在其他机器上有相同的备份，如果宕机的 broker 上有 partition 的 leader ，此时会在剩余的 follower 中**重新选举**出新的 leader

**写数据**的时候，生产者就写 leader，然后 leader 将数据落地写本地磁盘，接着其他 follower 自己主动从 leader 来 pull 数据，一旦所有 follower 同步好数据了，就会发送 ack 给 leader，leader 收到所有 follower 的 ack 之后，就会返回写成功的消息给生产者（其中一种模式，可以适当调整这个行为）

**消费**的时候，只会从 leader 去读，但是只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到

[关于 Kafka 架构](./MQ-Kafka.md)
